{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the main dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the main dataset\n",
    "data_path = 'data.xls'\n",
    "data = pd.read_excel(data_path)\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check if the first column is date and time, and drop it if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if the first column is date and time, and drop it if necessary\n",
    "if 'Date' in data.columns or 'Time' in data.columns:\n",
    "    data = data.drop(columns=['Date', 'Time'], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Select only numeric columns for PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns for PCA\n",
    "data_numaric = data.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Standardize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(data_numaric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Perform PCA with a large number of components to analyze variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA with a large number of components to analyze variance\n",
    "explained_variance_ratios = []\n",
    "for i in range(1, len(data_numaric.columns) + 1):\n",
    "    pca = PCA(n_components=i)\n",
    "    pca.fit(X_scaled)\n",
    "    explained_variance_ratios.append(np.sum(pca.explained_variance_ratio_))\n",
    "    print(f\"#Number of components: {i}, Explained variance: {explained_variance_ratios[-1]}\")\n",
    "\n",
    "plt.plot(range(1, len(data_numaric.columns) + 1), explained_variance_ratios, marker='o')\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance ratio')\n",
    "plt.title('Cumulative Variance Explained by PCA Components')\n",
    "plt.show()\n",
    "\n",
    "# Choose number of components based on variance explained (e.g., 18 components for ~88% variance)\n",
    "n_components = 18\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create a DataFrame for PCA results\n",
    "pca_columns = [f'PC{i+1}' for i in range(n_components)]\n",
    "pca_df = pd.DataFrame(data=X_pca, columns=pca_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Elbow method to determine the optimal number of clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method to determine the optimal number of clusters\n",
    "inertia = []\n",
    "K = range(1, 11)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K, inertia, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method For Optimal Number of Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Clustering using K-MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering using KMeans\n",
    "kmeans = KMeans(n_clusters=7, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to the PCA DataFrame\n",
    "pca_df['Cluster'] = clusters\n",
    "\n",
    "# 2D visualization of the first two principal components\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='Cluster', palette='viridis', data=pca_df)\n",
    "plt.title('PCA - Heat Pump Data with KMeans Clusters')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()\n",
    "\n",
    "# 3D visualization of the first three principal components\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pca_df['PC1'], pca_df['PC2'], pca_df['PC3'], c=pca_df['Cluster'], cmap='viridis')\n",
    "ax.set_title('3D PCA - Heat Pump Data with KMeans Clusters')\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "plt.show()\n",
    "\n",
    "# Silhouette Score to evaluate clustering\n",
    "silhouette_avg = silhouette_score(X_scaled, clusters)\n",
    "print(f'Silhouette Score: {silhouette_avg:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Plot heatmap of feature importance in PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap of feature importance in PCA\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "loadings_df = pd.DataFrame(loadings, columns=pca_columns, index=data_numaric.columns)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(loadings_df, annot=True, cmap='viridis')\n",
    "plt.title('PCA Loadings Heatmap')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Save the principal components to a CSV file if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the principal components to a CSV file if needed\n",
    "pca_df.to_csv('pca_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Scree plot and cumulative variance plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scree plot and cumulative variance plot\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, n_components + 1), explained_variance, alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(1, n_components + 1), cumulative_variance, where='mid', label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.title('Scree Plot and Cumulative Explained Variance')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Correlation circle for the first two principal components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation circle for the first two principal components\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.quiver(np.zeros(loadings.shape[0]), np.zeros(loadings.shape[0]), loadings[:, 0], loadings[:, 1], \n",
    "           angles='xy', scale_units='xy', scale=1)\n",
    "for i in range(loadings.shape[0]):\n",
    "    plt.text(loadings[i, 0], loadings[i, 1], data_numaric.columns[i], color='r')\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Correlation Circle for PCA')\n",
    "plt.grid()\n",
    "plt.axhline(0, color='grey', linestyle='--')\n",
    "plt.axvline(0, color='grey', linestyle='--')\n",
    "circle = plt.Circle((0, 0), 1, color='b', fill=False)\n",
    "plt.gca().add_artist(circle)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chandan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
